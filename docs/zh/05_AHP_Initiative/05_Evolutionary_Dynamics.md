# 05. 进化动力学：从启发式提示到确定性验证

## 摘要

AHP 不仅是一个静态的控制框架，更是一个具备自我进化能力的动态系统。本文阐述了 AHP 如何通过"知识演进管道"解决智能体上下文容量有限与工程约束无限增长之间的矛盾。通过将规则从 `AGENTS.md`（启发式提示）逐步卸载至 Agent Hooks（形式化验证），AHP 实现了 Just-in-Time Prompting 机制，在保持上下文简洁的同时，通过环境感知的即时干预降低系统熵值。

---

## 1. 核心矛盾：上下文腐烂 vs. 规则膨胀

### 1.1 认知的边际收益递减

随着项目的演进，工程团队积累了大量的最佳实践、安全约束和风格指南。传统的智能体治理倾向于将这些所有规则写入 System Prompt 或 `AGENTS.md`。

然而，大语言模型的注意力机制存在局限性：

- **竞争效应**：模型需要在"理解任务逻辑"与"遵守边缘规则"之间分配有限的注意力资源。
- **上下文腐烂**：随着 Prompt 长度增加，模型对特定指令的遵循率呈现非线性下降。
- **成本激增**：每个 Token 都会增加推理延迟和经济成本。

### 1.2 激活的不确定性

另一种扩展能力的方式是使用 Agent Skills（工具）。然而，工具的调用依赖于智能体的主动意图（Intent）。研究表明 [^1]，在缺乏明确引导的情况下，智能体往往会忽略可用工具，导致能力处于"休眠"状态。

这就构成了智能体工程的核心困境：**我们希望智能体遵守的规则越来越多，但智能体能够有效承载的上下文空间却是有限的。**

---

## 2. 理论模型：知识演进管道

为了打破上述困境，AHP 提出了一套知识从"软约束"向"硬门禁"流动的演进机制。

### 2.1 演进三阶段

```mermaid
graph LR
    A[失效模式发现] -->|自然语言描述| B(AGENTS.md: 启发式提示)
    B -->|规则固化| C(Agent Hooks: 形式化验证)
    C -->|上下文卸载| D[保持上下文纯净]
```

#### 阶段一：发现 (Discovery)

通过分析 AHP 记录系统（Issue Tickets）中的交互历史，识别反复出现的失效模式（Failure Patterns）。

- _例子_：智能体经常在修改 API 后忘记更新文档。

#### 阶段二：孵化 (Incubation / Heuristic)

将新发现的规则以自然语言形式写入 `AGENTS.md`。

- _形式_：`"规则：修改 API 代码时，必须同步更新相应的文档。"`
- _优势_：部署快，灵活性高，利用 LLM 的通用理解力。
- _劣势_：占用上下文，依赖模型自觉遵守。

#### 阶段三：固化与卸载 (Formalization & Offloading)

当规则足够稳定且可以通过代码逻辑描述时，将其转化为 **Oracle** 并挂载到 **Hook** 上，同时从 `AGENTS.md` 中删除该规则。

- _形式_：编写 `DocumentationOracle`，在 `pre-issue-submit` 阶段自动检查 API 变更与文档变更的对应关系。
- _优势_：零上下文占用，100% 执行率，确定性反馈。

### 2.2 演进的判据

并非所有知识都适合形式化。只有满足以下特征的规则才应进入 Hooks：

1.  **可检测性 (Detectability)**：触发条件有明确的代码特征（如文件路径、AST 变更）。
2.  **高频性 (Frequency)**：该错误频繁发生，值得编写专门代码。
3.  **确定性 (Determinism)**：判断标准清晰，误报率低。

对于模糊的、创造性的建议（如"代码应具有良好的可读性"），仍应保留在 `AGENTS.md` 中。

---

## 3. 机制创新：Hooks 作为 JIT Prompting

### 3.1 动态上下文注入

Agent Hooks 不仅仅是拦截器，本质上是一种 **Just-in-Time (JIT) Prompting** 机制。它通过识别环境模式，判别智能体当前所处的特定情境，从而注入最恰当的提示。

| 机制            | 触发方式 | 时机          | 效果                     |
| :-------------- | :------- | :------------ | :----------------------- |
| **AGENTS.md**   | 静态加载 | 会话开始时    | 全局提示，容易被遗忘     |
| **Agent Hooks** | 动态触发 | 错误发生前/后 | 局部提示，精准且印象深刻 |

### 3.2 熵减效应

在热力学中，熵代表系统的混乱度。智能体在执行任务时，随着步骤增加，偏离目标的概率（熵）往往会增加。

Hooks 通过在关键节点（状态转换）引入负熵（Negative Entropy）：

- **剪枝**：通过 `Blocking` 信号，剪除错误的决策分支。
- **纠偏**：通过 `Prompting` 信号，将智能体的注意力拉回正确轨道。

```
执行轨迹：
Start ──► Step 1 ──► Step 2 (偏差) ──► [Hook 触发: JIT 提示] ──► Step 2 (修正) ──► Goal
                                              ▲
                                              └─ 熵减干预
```

---

## 4. 治理的精细化：基于遥测的动态适应

### 4.1 Hooks 作为传感器

在 AHP 框架中，Hooks 不仅是执行点，更是系统的**遥测传感器（Telemetry Sensors）**。每一个信号的生成、消费和结果都应被结构化记录：

-   **触发频率 (Trigger Frequency)**：识别哪些规则是高频触发的热点。
-   **修正耗时 (Mean Time to Repair, MTTR)**：智能体在收到 `Blocking` 或 `Prompting` 信号后，平均需要多少次尝试才能通过验证。
-   **忽略率 (Dismissal Rate)**：对于 `Prompting` 级别的信号，智能体选择“忽略”的比例。

### 4.2 规则的 ROI 评估

通过聚合统计分析，运营人员可以评估规则的适用性：
-   **高频触发 + 高忽略率**：说明该提示可能过于繁琐或不合时宜，属于“无效噪音”，应优化触发条件或降级。
-   **高触发 + 长修正耗时**：说明该领域是智能体的“认知盲区”，仅靠 Hook 拦截不够，应加强 `AGENTS.md` 中的背景知识注入或开发专项 Skill。
-   **零触发**：说明规则可能已过时，或者防御的失效模式在当前架构下已不存在，应考虑清理以维持系统简洁。

---

## 5. 闭环反馈：智能体的主动申诉机制

### 5.1 智能体作为系统观测者

演进不应只是“人对智能体”的单向治理。AHP 引入了基于 `MEMO.md` 的**主动反馈机制**，赋予智能体对 Harness 系统本身的评价能力。

当智能体在执行任务时感受到以下压力，它可以主动写入 `MEMO.md`：
-   **约束冲突**：例如，`AGENTS.md` 要求保持函数短小，但 Hook 逻辑在特定复杂场景下导致了不必要的代码拆分。
-   **流程堵点 (Bottlenecks)**：某些 Hook 验证耗时过长，或反馈信息模糊，阻碍了任务进度。
-   **最佳实践演进**：智能体在处理最新版本的第三方库时，发现 `AGENTS.md` 中的建议已不再适用。

### 5.2 反馈处理流

1.  **记录**：智能体记录堵点，附带上下文证据，然后继续工作。
2.  **消费**：项目维护者或 Architect 智能体定期审查 `MEMO.md`。
3.  **响应**：根据反馈调整 Hook 强度、更新 `AGENTS.md` 或优化 Skills，实现 Harness 系统与业务需求的动态对齐。

---

## 6. 案例研究：从建议到铁律，再到反馈循环

**场景：禁止在该项目中使用 `print` 进行调试，强制使用 `logger`。**

### 演进与反馈闭环

1.  **初始状态**：智能体大量使用 `print`，导致生产日志混乱。
2.  **AGENTS.md 阶段**：添加 `"禁止使用 print()，必须使用 logging 模块"`。
3.  **Hooks 阶段**：编写 `NoPrintOracle`，在 `pre-issue-submit` 触发 `Blocking`。
4.  **遥测阶段**：发现该 Hook 触发频率极高，但 MTTR 很短（智能体能瞬间修复）。这说明规则明确但容易被遗忘。
5.  **反馈阶段**：智能体在 `MEMO.md` 记录：_"在快速原型开发（Spike 类型 Issue）时，强制使用 logger 增加了样板代码开销，建议对 Spike 类型任务放宽限制。"_
6.  **优化阶段**：调整 Hook 触发逻辑，仅在 `feature` 和 `fix` 类型任务中强制拦截，在 `spike` 类型中改为 `Prompting`。

---

## 7. 结论

AHP 的进化动力学机制解决了智能体工程的可持续性问题。通过建立知识演进管道、遥测分析机制和智能体反馈闭环，我们能够：

1.  **最大化智能体效能**：让智能体专注于任务本身，而非记忆繁琐的规则。
2.  **最小化环境熵**：通过 JIT Prompting 实现高精度的过程控制。
3.  **精细化工程治理**：利用遥测指标指导规则的去冗余与强度调节。
4.  **建立双向契约**：通过 `MEMO.md` 使 Harness 系统具备感知业务需求变更的能力，实现人、智能体与协议的共同演进。

---

## 参考

[^1]: Vercel. "Agents.md outperforms Skills in our agent evals".
