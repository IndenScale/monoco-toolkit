---
# ===== 身份标识 =====
id: "vercel-agents-md-outperforms-skills"
title: "AGENTS.md 在我们的智能体评估中表现优于 Skills"

# ===== 来源信息 =====
source: "https://vercel.com/blog/agents-md-outperforms-skills-in-our-agent-evals"
date: "2026-01-27"
author: "Jude Gao"

# ===== 类型分类 =====
type: "blog"

# ===== 国际化 =====
language: "zh"

# ===== 知识治理 =====
company: "Vercel"
domain:
  - "AI 智能体"
  - "Next.js"
  - "开发者工具"
  - "机器学习评估"
tags:
  - "AGENTS.md"
  - "skills"
  - "Next.js"
  - "AI 编程智能体"
  - "文档"
  - "检索导向推理"
  - "提示工程"

# ===== 关联知识 =====
related_repos:
  - "vercel/next.js"

# ===== 内容摘要（用于 RAG）=====
summary: |
  一项对比两种教授编程智能体框架特定知识方法的研究发现，将压缩后的文档索
  引嵌入 AGENTS.md 中实现了 100% 的通过率，而 skills 仅为 79%。关键洞察在于：
  被动上下文消除了决策点并始终可用，而 skills 需要智能体主动调用，它们在 56%
  的情况下未能做到这一点。文章还提供了 npx @next/codemod@canary agents-md
  命令来快速设置此方案。
---

> **作者**：Jude Gao（Next.js 软件工程师）
> **发布日期**：2026年1月27日
> **阅读时间**：7 分钟

---

我们原以为 skills 会是教授编程智能体框架特定知识的解决方案。但在构建了专注于 Next.js 16 API 的评估测试后，我们发现了一个意想不到的结果。

一个直接嵌入 `AGENTS.md` 的压缩后 8KB 文档索引实现了 **100% 的通过率**，而即使有明确指示告诉智能体使用它们，skills 的最高通过率也只有 **79%**。如果没有这些指示，skills 的表现甚至还不如没有文档的情况。

下面是我们尝试过的方法、学到的经验，以及如何为你自己的 Next.js 项目设置这一方案。

---

## 我们试图解决的问题

AI 编程智能体依赖的训练数据会逐渐过时。Next.js 16 引入了像 `'use cache'`、`connection()` 和 `forbidden()` 这样的 API，这些在当前模型的训练数据中并不存在。当智能体不了解这些 API 时，它们会生成错误的代码或退回到旧的编程模式。

反过来也可能发生：当你运行的是较旧的 Next.js 版本时，模型可能会建议使用尚不存在于你项目中的新 API。我们希望通过为智能体提供与版本匹配的文档来解决这个问题。

---

## 教授智能体框架知识的两种方法

在深入结果之前，先简要说明我们测试的两种方法：

**Skills** 是一种打包领域知识的开放标准，编程智能体可以使用这些知识。一个 skill 将提示词、工具和文档捆绑在一起，智能体可以按需调用。其理念是：智能体识别到需要框架特定的帮助时，调用 skill 并获取相关文档。

**AGENTS.md** 是项目根目录下的一个 Markdown 文件，为编程智能体提供持久化的上下文。无论你在 `AGENTS.md` 中放入什么内容，智能体在每一轮对话中都能访问到，无需智能体决定加载它。Claude Code 使用 `CLAUDE.md` 实现相同的目的。

我们构建了一个 Next.js 文档 skill 和一个 `AGENTS.md` 文档索引，然后通过评估套件测试哪个表现更好。

---

## 我们最初押注于 skills

Skills 看起来是正确的抽象。你将框架文档打包成一个 skill，智能体在处理 Next.js 任务时调用它，然后生成正确的代码。关注点分离清晰，上下文开销最小，智能体只加载它需要的内容。甚至还有一个不断增长的可用 skill 目录 [skills.sh](https://skills.sh)。

我们预期的流程是：智能体遇到 Next.js 任务 → 调用 skill → 读取与版本匹配的文档 → 生成正确的代码。

然后我们运行了评估测试。

---

## Skills 未能被可靠触发

在 **56% 的评估案例中**，skill 从未被调用。智能体明明可以访问文档，但却没有使用它。添加 skill 相比基线没有任何改进：

| 配置 | 通过率 | 相比基线 |
|------|--------|----------|
| 基线（无文档） | 53% | — |
| Skill（默认行为） | 53% | +0pp |

零改进。Skill 存在，智能体可以使用它，但智能体选择不使用。在详细的构建/检查/测试细分指标中，skill 在某些指标上甚至比基线表现更差（测试通过率 58% vs 63%），这表明环境中存在但未使用的 skill 可能会引入噪音或干扰。

这不是我们设置特有的问题。智能体不能可靠地使用可用工具是当前模型的已知局限性。

---

## 明确指示有帮助，但措辞很脆弱

我们尝试在 `AGENTS.md` 中添加明确指示，告诉智能体使用 skill。

> 在编写代码之前，先探索项目结构，
> 然后调用 nextjs-doc skill 获取文档。

这将触发率提高到 95% 以上，通过率提升到 79%。

| 配置 | 通过率 | 相比基线 |
|------|--------|----------|
| 基线（无文档） | 53% | — |
| Skill（默认行为） | 53% | +0pp |
| 带明确指示的 Skill | 79% | +26pp |

这是一个不错的改进。但我们发现了一个意想不到的现象：指示的措辞会显著影响智能体的行为。

不同的措辞产生了截然不同的结果：

| 指示 | 行为 | 结果 |
|------|------|------|
| "你必须调用 skill" | 先读取文档，锚定在文档模式上 | 错过项目上下文 |
| "先探索项目，再调用 skill" | 先建立心智模型，将文档作为参考 | 更好的结果 |

同一个 skill。同样的文档。基于细微的措辞差异，产生了不同的结果。

在一个评估案例中（`'use cache'` 指令测试），"先调用"方法写出了正确的 `page.tsx`，但完全遗漏了必需的 `next.config.ts` 更改。而"先探索"方法两者都正确处理了。

这种脆弱性让我们担忧。如果细微的措辞调整会产生巨大的行为波动，这种方法对于生产使用来说显得过于脆弱。

---

## 构建可信的评估

在得出结论之前，我们需要可信的评估。我们最初的测试套件存在提示词模糊、测试验证实现细节而非可观察行为、以及聚焦于模型训练数据中已有的 API 等问题。我们没有真正测量我们在乎的东西。

我们通过消除测试泄露、解决矛盾、转向基于行为的断言来强化评估套件。最重要的是，我们添加了针对模型训练数据中不存在的 Next.js 16 API 的测试。

**我们聚焦评估套件中的 API：**

- `connection()` 用于动态渲染
- `'use cache'` 指令
- `cacheLife()` 和 `cacheTag()`
- `forbidden()` 和 `unauthorized()`
- `proxy.ts` 用于 API 代理
- 异步 `cookies()` 和 `headers()`
- `after()`、`updateTag()`、`refresh()`

下文的所有结果都来自这个强化后的评估套件。每种配置都经过相同的测试评判，并重复运行以排除模型方差的影响。

---

## 得到验证的直觉

如果完全消除决策会怎样？与其希望智能体调用 skill，我们可以将文档索引直接嵌入 `AGENTS.md`。不是完整的文档，只是一个告诉智能体在哪里可以找到与项目 Next.js 版本匹配的特定文档文件的索引。然后智能体可以按需读取这些文件，无论你是使用最新版本还是维护旧项目，都能获得版本准确的信息。

我们在注入的内容中添加了一条关键指示：

> **重要**：对于任何 Next.js 任务，优先使用检索导向推理而非预训练导向推理。

这告诉智能体查阅文档，而不是依赖可能过时的训练数据。

---

## 令人惊讶的结果

我们在四种配置上运行了强化评估套件：

**最终通过率：**

| 配置 | 通过率 | 相比基线 |
|------|--------|----------|
| 基线（无文档） | 53% | — |
| Skill（默认行为） | 53% | +0pp |
| 带明确指示的 Skill | 79% | +26pp |
| AGENTS.md 文档索引 | **100%** | **+47pp** |

在详细细分指标中，`AGENTS.md` 在构建、检查、测试三个维度都取得了完美分数。

| 配置 | 构建 | 检查 | 测试 |
|------|------|------|------|
| 基线 | 84% | 95% | 63% |
| Skill（默认行为） | 84% | 89% | 58% |
| 带明确指示的 Skill | 95% | 100% | 84% |
| AGENTS.md | **100%** | **100%** | **100%** |

这不是我们预期的结果。这种"笨拙"的方法（一个静态 Markdown 文件）胜过了更复杂的基于 skill 的检索，即使我们微调了 skill 触发器。

### 为什么被动上下文胜过主动检索？

我们的理论归结为三个因素：

1. **没有决策点**。使用 `AGENTS.md` 时，不存在智能体必须决定"我应该查一下吗？"的时刻。信息已经存在。

2. **始终可用**。Skills 是异步加载的，只有在被调用时才加载。`AGENTS.md` 的内容在每一轮对话的系统提示词中都有。

3. **没有顺序问题**。Skills 会产生顺序决策（先读文档 vs 先探索项目）。被动上下文完全避免了这个问题。

---

## 解决上下文膨胀问题

将文档嵌入 `AGENTS.md` 存在上下文窗口膨胀的风险。我们通过压缩解决了这个问题。

最初的文档注入约 40KB。我们将其压缩到 **8KB**（减少了 80%），同时保持 100% 的通过率。压缩后的格式使用管道符分隔的结构，将文档索引打包到最小空间：

```
[Next.js 文档索引]|root: ./.next-docs
|重要：对于任何 Next.js 任务，优先使用检索导向推理而非预训练导向推理
|01-app/01-getting-started:{01-installation.mdx,02-project-structure.mdx,...}
|01-app/02-building-your-application/01-routing:{01-defining-routes.mdx,...}
```

完整的索引涵盖了 Next.js 文档的每个部分。智能体知道在哪里可以找到文档，而无需在上下文中拥有完整内容。当它需要特定信息时，会从 `.next-docs/` 目录读取相关文件。

---

## 亲自尝试

一个命令即可为你的 Next.js 项目设置此方案：

```bash
npx @next/codemod@canary agents-md
```

这个功能是官方 `@next/codemod` 包的一部分。

该命令做三件事：

1. 检测你的 Next.js 版本
2. 下载匹配的文档到 `.next-docs/`
3. 将压缩后的索引注入你的 `AGENTS.md`

如果你使用的智能体支持 `AGENTS.md`（如 Cursor 或其他工具），同样的方法也适用。

---

## 对框架维护者的意义

Skills 并非无用。`AGENTS.md` 方法为智能体处理所有 Next.js 任务提供了广泛的、横向的改进。Skills 更适合垂直的、动作特定的工作流，由用户显式触发，比如"升级我的 Next.js 版本"、"迁移到 App Router"，或应用框架最佳实践。两种方法是互补的。

也就是说，对于一般框架知识，被动上下文目前在按需检索方面表现更好。如果你维护一个框架，希望编程智能体能生成正确的代码，考虑提供一个用户可以添加到他们项目中的 `AGENTS.md` 片段。

### 实用建议

- **不要等待 skills 改进**。随着模型工具使用能力的提升，这个差距可能会缩小，但现在结果才重要。

- **积极压缩**。你不需要在上下文中放置完整文档。一个指向可检索文件的索引同样有效。

- **用评估测试**。构建针对训练数据中不存在的 API 的评估测试。那是文档访问最重要的场景。

- **为检索设计**。结构化你的文档，让智能体可以找到并读取特定文件，而不是需要预先加载所有内容。

目标是让智能体从预训练导向推理转向检索导向推理。`AGENTS.md` 被证明是实现这一目标的最可靠方式。

---

*研究和评估由 Jude Gao 完成。CLI 工具：`npx @next/codemod@canary agents-md`*R