# 00. 定义与层级

## 1. 演进历程：从对话到自主系统

智能体系统的演进并非单一技术的突破，而是能力的逐层叠加过程。从 2020 年的纯文本模型到今天的自主系统，这一历程展示了如何通过工程实践将基础模型能力转化为可靠的自主执行能力。
2020 年，GPT-3 的发布标志着大语言模型进入公众视野。这些模型本质上是无状态的函数：给定上下文，输出补全文本。它们没有记忆，不能执行操作,只是纯粹的文本处理器。在这个阶段，大语言模型的应用主要限于 API 调用形式，开发者需要自行管理上下文和交互逻辑。2022 年末，ChatGPT 的发布改变了这一局面。OpenAI 将大语言模型封装为对话产品，引入了对话历史管理和用户界面,让普通用户可以通过多轮交互获取信息。随后 Claude.ai、Gemini 等类似产品陆续发布。这些产品的核心特征是人类驱动每一轮交互：用户提问，系统回答，然后等待下一个问题。系统记住之前的对话内容作为上下文，但仍然无法执行任何外部操作，只能生成文本响应。
2023 年，Function Calling 能力的引入让大语言模型可以调用外部工具。这一突破催生了新一代编程助手产品，如 Cursor、GitHub Copilot、Gemini CLI、Claude Code 等。这些产品将工具调用能力应用于编程场景，让 AI 可以直接读写文件、执行命令、运行测试和构建项目。它们通常被称为"AI Agent"，能够进行多步骤规划并逐步执行复杂任务。尽管仍然需要人类在每个关键节点进行确认和指导，但这些系统已经可以自主完成相当复杂的工作。在这个阶段，一个重要的术语歧义开始出现。对于对话产品，人们习惯称一次完整的对话为"session"，但这只是多轮人机交互的集合，每一轮仍然需要人类的主动输入。真正的 session 应该指一次无人工介入的自主运行过程——从启动到完成目标或失败退出。这种术语的混用在后续的系统设计中造成了一定的概念混乱。
同期，AutoGPT、MetaGPT 等项目尝试构建完全自主的系统，让 AI 可以独立完成复杂任务而无需人类持续指导。然而，这些早期尝试大多以失败告终。主要原因在于它们缺乏质量保证机制，没有自动化测试和验证框架。同时，这些系统与人类共享工作环境，容易产生状态冲突和污染。任务状态存储在内存中，无法持久化和恢复，导致系统的稳定性和可靠性都无法满足实际需求。2024 年至今，Manus、OpenClaw 等新一代产品开始引入工程化实践。这些系统使用容器或虚拟机提供独立的工作环境，避免了与人类工作空间的冲突。它们将任务状态存储在文件系统中，实现了持久化管理。更重要的是，它们集成了自动化测试和质量检查机制，为自主运行提供了基本的质量保障。
这一演进过程揭示了一个核心洞察：自主系统的构建不依赖于模型能力的革命性突破，而是通过系统化的工程实践——环境隔离、状态持久化、质量保证——将现有的工具调用能力提升为可靠的自主执行能力。Monoco 的目标正是在此基础上，通过定义严格的协议和约束，将这些工程实践标准化为可复用的系统架构。

## 2. 能力层级与渐进改进

上述演进过程可以抽象为四个能力层级。理解这些层级的关键在于：它们之间没有本质的技术鸿沟。低层级系统可以通过渐进的工程改进获得高层级系统的特性，而不需要等待 AI 模型本身的革命性突破。

### L0: 大语言模型

最基础的层级是大语言模型本身，以 API 形式提供服务。典型代表包括 GPT-4、Claude 3.5、Gemini 2.0 的 API 接口。这一层级的核心能力是文本输入到文本输出的映射。每次 API 调用都是独立的，模型不保留任何历史信息，也不会产生任何副作用。模型的所有"知识"都来自训练数据和当前请求中提供的上下文。

### L1: 对话机器人

第一个能力跃升来自对话历史管理和用户界面的引入。ChatGPT、Claude.ai、Gemini 等产品在 L0 的基础上添加了对话历史存储（通过数据库或文件系统）、会话管理逻辑以及 Web 或移动端界面。这使得系统可以维护多轮交互的上下文，理解用户在对话过程中的指代关系和话题演进。然而，每轮交互仍然需要人类的主动输入来驱动，系统的主要用途是信息检索、问答和内容生成。

从工程角度看，L0 到 L1 的跃升并不涉及模型能力的改变，而是在模型外围添加了状态管理和交互界面。这一改进是纯粹的软件工程问题。

### L2: 智能体

第二个能力跃升来自外部工具调用和多步骤规划能力的引入。Cursor、Gemini CLI、Claude Code 等产品在 L1 的基础上添加了工具调用框架（Function Calling）、文件系统和命令行接口，以及任务规划和执行逻辑。这使得系统可以操作外部环境，读写文件、执行命令、运行测试。系统可以将复杂任务分解为多个步骤，并按顺序执行，但关键操作通常需要人类的确认。

值得强调的是，即使是简单的工具调用智能体，也可以通过以下工程实践获得部分自主能力。Pre-commit hooks 可以在提交前自动运行 linter 和测试，GitHub Actions 可以自动化 CI/CD 流程，测试覆盖率要求可以强制代码通过测试才能合并，代码审查规则可以定义明确的验收标准。这些实践让"智能体加环境"的组合具备了基本的质量保证能力，而无需等待 AI 模型本身变得"更智能"。

### L3: 自主系统

第三个能力跃升来自协议约束、环境隔离和状态持久化的系统化应用。Monoco 的目标态、Manus、OpenClaw 等产品在 L2 的基础上添加了容器化或虚拟化环境、任务状态文件系统（如 Issue 文件）、自动化测试和验证框架，以及失败重试和恢复机制。这使得系统拥有独立的工作空间，不会污染人类的工作环境。任务状态存储在外部文件中，可以跨 session 恢复。通过明确的验收标准（Definition of Done）和不变量（Invariants），系统可以自主判断任务是否完成以及质量是否达标。一次 session 可以完整执行任务，从启动到达成目标或失败退出，期间无需人类介入。

从 L2 到 L3 的演进路径同样是渐进的。一个 L2 系统可以通过以下步骤演进为 L3：首先,引入 Issue 跟踪系统，将任务状态从内存移到文件，实现持久化。其次，配置 Git hooks，在提交时自动运行质量检查。第三，为每个任务类型定义验收标准，明确什么样的结果才算完成。第四，实现自动化测试，确保代码变更不破坏现有功能。最后，添加环境隔离，使用 Git worktree 或容器隔离工作空间，避免状态污染。

## 3. 关键概念的语义演进

随着系统能力的提升，一些基础概念的含义也在演进。理解这些语义变化对于准确定义自主系统至关重要。

在对话产品中，"prompt"指的是用户的提问或指令，是人类主动输入的内容。而在自主系统中，prompt 的含义扩展为系统向智能体注入的上下文约束。这包括配置文件（如 `GEMINI.md`），它们定义了系统的行为规范和策略；任务描述（Issue 文件），它们明确了当前需要完成的工作；以及质量反馈（linter 错误、测试失败消息），它们为智能体提供了自我修正的依据。Prompt 不再仅仅是人类的输入，而是整个系统环境对智能体的约束总和。

"产物"的定义也发生了根本变化。在对话产品中，对话内容本身就是产物，用户获取的价值就是 AI 的回答。而在自主系统中，只有可验证的工件才是产物。代码必须通过测试，文档必须符合规范，构建必须成功。对话历史只是生成过程的副产品，记录了系统如何到达当前状态，但不是交付给用户的价值本身。这一转变意味着自主系统的质量标准从"回答是否令人满意"转变为"产物是否满足客观标准"。

"Session"的语义演进尤为重要。在对话产品中，人们习惯将一系列人机交互轮次的集合称为 session，比如"一次对话 session"。但这实际上是对术语的误用，因为每一轮都需要人类的输入，系统本身并没有自主运行的能力。在自主系统中，session 指的是智能体的一次完整自主运行，从启动到达成目标或失败退出，期间无人工介入。这是一个明确的、可度量的概念：session 的开始是系统接收任务，结束是系统返回结果或报告失败，中间的所有决策都由系统自主完成。

## 4. 交互模式的转变

不同层级的系统对应不同的人机交互模式，这些模式决定了系统能够带来的效率提升上限。

- Human-In-The-Loop（HITL）是 L1 和 L2 系统的典型交互模式。在这种模式下，人类参与每个关键决策，需要持续监督和纠正系统的行为。一个典型场景是使用 Cursor 编程：AI 生成代码，人类审查并修改，然后 AI 根据反馈继续生成。这种模式下，效率提升通常是有限的，一般在 1.5 到 3 倍之间。原因在于人类的监督成本：虽然 AI 承担了大部分编写工作，但人类仍然需要理解和验证每一步输出，这消耗了大量时间和注意力。
- Human-On-The-Loop（HOTL）是 L3 系统的典型交互模式。在这种模式下，人类只在开始和结束时介入：在开始时定义任务和验收标准，在结束时验收最终产物。系统在中间过程中自主执行和自我验证，无需人类持续关注。一个典型场景是：创建 10 个 Issue，每个 Issue 都有明确的 Definition of Done 和测试要求，系统自主完成所有 Issue 并通过测试，人类只需在最后进行整体验收。这种模式下，效率提升可以是数量级的，达到 10 倍甚至更高。关键在于人类的注意力得到了解放：在系统运行期间，人类可以去做其他工作，或者同时监督多个系统的运行。

这两种模式的区别不仅仅是效率数字的差异，更是工作方式的本质转变。HITL 模式下，人类是执行者，AI 是助手。HOTL 模式下，AI 是执行者，人类是监督者。后者需要系统具备自我验证和质量保证能力，这正是 L3 系统相对于 L2 系统的核心优势。

## 5. 层级对比

| 维度         | L0: 大语言模型 | L1: 对话产品             | L2: 工具调用智能体    | L3: 自主系统           |
| ------------ | -------------- | ------------------------ | --------------------- | ---------------------- |
| 核心能力     | 文本生成       | 多轮对话                 | 环境操作              | 自主任务执行           |
| 状态管理     | 无状态         | 对话历史（内存）         | 对话历史 + 工作区状态 | 持久化任务状态（文件） |
| 环境         | 无             | 无                       | 共享人类环境          | 隔离环境               |
| 质量保证     | 无             | 无                       | 人类审查              | 自动化测试 + 协议约束  |
| 交互模式     | 单次调用       | HITL（每轮）             | HITL（关键节点）      | HOTL                   |
| Session 定义 | 不适用         | 不适用（误用为交互轮次） | 一次任务执行          | 一次完整自主运行       |
| 失败处理     | 返回错误       | 人类重新提问             | 人类介入修复          | 自动重试或回滚         |
| 典型产品     | GPT-4 API      | ChatGPT                  | Cursor, Claude Code   | Monoco, Manus          |
| 效率提升     | N/A            | 1-2x                     | 1.5-3x                | 10x+                   |

## 6. Monoco 的定位

Monoco 的目标是构建 L3 级别的自主开发系统。区别于对话产品和工具调用智能体，自主系统的本质在于四个理论要素的有机结合：

- **Definition of Done（DoD）**：定义了任务完成的客观标准。在对话产品中，任务是否完成取决于人类的主观满意度；在工具调用智能体中，每个关键节点都需要人类判断是否继续。而在自主系统中，DoD 将完成标准显式化为可机器验证的规则：测试必须通过，linter 不能报错，构建必须成功。智能体通过检查这些客观指标自主判断任务是否达标，无需人类介入每个决策点。
- **Ascending Milestone（渐进里程碑）**：将复杂任务分解为可验证的阶段。每个里程碑都有自己的 DoD，智能体完成一个里程碑后自动进入下一个。这种结构化的任务分解使得系统可以在长时间运行中保持方向，避免在复杂任务中迷失。更重要的是，里程碑的设置使得系统可以在任意阶段暂停和恢复，因为每个里程碑的完成状态都是可持久化、可验证的。
- **System Invariance（系统不变量）**：确保系统在运行过程中维持一致性约束。这些不变量包括代码库的完整性（所有测试通过）、环境的隔离性（不污染主工作区）、状态的可恢复性（任务信息存储在 Issue 文件中）。每次智能体执行操作后，系统都会验证这些不变量是否被破坏。如果不变量被违反，系统会自动回滚或报告失败，而不是将错误状态传播到后续步骤。这种机制使得自主系统具备了基本的"自我保护"能力。
- **Ralph Loop（拉尔夫循环）**：自主系统的核心执行模式。在每个循环中，智能体根据当前任务和环境状态生成行动计划，执行操作，验证 DoD 和系统不变量，然后根据验证结果决定下一步行动。这个循环在无人工介入的情况下持续进行，直到所有里程碑完成或遇到无法自动恢复的失败。与 HITL 模式的本质区别在于：人类不在循环内部，而是在循环开始前定义任务和验收标准，在循环结束后验收最终产物。

Monoco 通过 Issue 文件系统实现这四个要素的具体化。每个 Issue 包含任务描述、DoD 定义、当前里程碑状态和相关文件列表。系统通过 Git hooks 强制执行不变量检查，通过自动化测试验证 DoD，通过 worktree 实现环境隔离。这意味着即使使用 Cursor 或 Claude Code 这样的 L2 工具，只要配合 Monoco 的协议和工作流，就可以获得接近 L3 的自主能力。关键不在于 AI 模型本身变得"更智能"，而在于工程实践将智能体嵌入到一个结构化的自主执行框架中。
